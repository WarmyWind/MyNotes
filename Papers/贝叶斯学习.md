# 贝叶斯学习

## 一、 预测不确定性

模型的预测不确定性（Prediction Uncertainty）来自两方面，认知不确定性（Epistemic Uncertainty，也称模型不确定性）和随机不确定性（Aleatoric Uncertainty，也称数据不确定性）。认知不确定性来源于模型学习，随机不确定性为数据所固有的（比如噪声）。

为了具体说明不确定性的概念，简单起见假设模型的输入输出都是标量。对于输入$x$，我们的模型输出为
$$
\hat y = f\left( x \right)
$$
模型不确定性${EU}$可以通过预测值的方差来度量，即
$$
EU = \operatorname{var} \left[ {\hat y} \right]
$$
随机不确定性$AU$通常被建模为高斯噪声，其不确定性大小为噪声方差
$$
AU = {\sigma ^2}
$$
预测不确定性为模型不确定性和随机不确定性两者之和
$$
PU = EU + AU
$$

### 1.1 可以量化不确定性的学习方法

本篇总结的内容和结构如下

<img src="C:\Users\WarmyWind\Desktop\绘图\visio绘图\贝叶斯学习目录.jpg" alt="贝叶斯学习目录" style="zoom: 67%;" />

本篇内容以介绍方法为主，文中所提到的方法也只是不确定性度量方法中的冰山一角，我选取了我认为较为基础和较为流行的方法来以偏概全。

除了方法以外，还有很多其他的重要问题，比如

- 如何评价度量的不确定性是否准确？
- 这些方法相互比较有何优劣？
- 不同的问题、场景更适合哪种方法？

对于这些问题，由于我的理解和实践尚不深入，无法进行整理。有待后续进一步学习和实践来更新这部分内容。



## 二、 贝叶斯神经网络（Bayesian Neural Network，BNN）

与传统的神经网络不同，BNN的权重并非确定值，而是随机量。对于一个确定的输入，BNN的输出是一个随机变量。用$f$表示BNN模型，$W$表示模型参数。以单输入单输出的预测任务为例，对于一个输入$x$，预测值$\hat y$为
$$
\hat y = f\left( {x\left| W \right.} \right)
$$
其中模型参数$W$是一个随机矢量，因此预测值$\hat y$也是随机变量。

### 2.1 贝叶斯推断

对于某个随机变量，我们在实际中往往很难确定其真实的分布，因此我们只能通过一些方法来“推断”（inference）它的分布。在贝叶斯学习中，我们通过创造某个分布来推断其分布，其工具就是贝叶斯公式。

假如$X$是一个随机变量，我们不知道其真实分布，我们只能观察到一个与$X$相关的随机变量$Y$。贝叶斯推断的主要流程如下：

1. 根据我们对$X$的知识，为$X$选择先验分布$p\left( X \right)$
2. 根据对$X$与$Y$之间依赖关系的知识，选择统计模型$p\left( {Y\left| X \right.} \right)$
3. 观察到$Y = y$
4. 利用贝叶斯公式更新$X$的后验分布

$$
p\left( {X\left| {Y = y} \right.} \right) = \frac{{p\left( {y\left| X \right.} \right)p\left( X \right)}}{{\int {p\left( {y\left| {X'} \right.} \right)p\left( X \right)dX'} }}
$$

贝叶斯推断的应用范围很宽泛，比如我们可以对神经网络中的参数分布做推断，或是对高斯过程中的诱导点分布做推断。在后面我们将看到贝叶斯推断具体是如何应用到BNN的训练中的。

### 2.2 基于变分推断（Variational Inference，VI）的BNN实现方法

> 这部分内容可以参考《Weight Uncertainty in Neural Networks》,Charles Blundell等著。

要实现一个BNN模型，我们首先决定神经网络结构，比如隐藏层深度、各个层的维度、激活函数等等，这一步与所要预测的任务有关。之后，我们的目标是根据训练集确定BNN的网络参数$W$。从贝叶斯的视角看，在给定训练集$D$时，后验$p\left( {W|D} \right)$的计算式为
$$
p\left( {W|D} \right) = \frac{{p\left( {D|W} \right)p\left( W \right)}}{{p\left( D \right)}} = \frac{{p\left( {D|W} \right)p\left( W \right)}}{{\smallint p\left( {D|W} \right)p\left( {W} \right)dW}}
$$
其中想要求$p\left( D \right)$这一项，需要对$p\left( {D,W} \right)$关于$W$进行积分，难以直接求得，因此我们需要近似求解方法。下面我们说明如何通过VI来求解。

我们回顾DNN的网络训练方式，网络参数有一个初始化值，然后通过梯度下降法逐渐收敛到（局部）最优点。既然无法直接求出$W$的分布，那么可不可以效仿DNN的思路，给$W$一个初始分布，然后逐步迭代收敛到一个较优的分布呢？VI实际上就是以此思路，将求$W$的分布这一泛函问题变为优化问题，使得我们能够用优化问题的方法（如梯度下降）来近似求解。

根据上述思路，我们需要给$W$确定一个初始分布（先验）$q\left( W \right)$并不断迭代，最终能够很好地近似$p\left( {W|D} \right)$。我们需要解决下面三个问题：

- $$q\left( W \right)$$的具体形式是什么
- 如何度量$q\left( W \right)$和$p\left( {W|D} \right)$的近似程度
- 如何迭代训练$$q\left( W \right)$$

对于第一个问题，我们常常假设$W$是高斯矢量：$q\left( W \right) = \mathcal{N}\left( {{\mathbf{\mu }},\Sigma } \right)$，并且各个维度之间互不相关（协方差阵$\Sigma $是对角阵）。在这种假设下的VI我们称为高斯平均场VI（Gaussian Mean-field VI）。

对于第二个问题，我们借助KL散度来度量$q\left( W \right)$和$p\left( {W|D} \right)$的近似程度，KL散度的定义式为：
$$
KL\left[ {p\left( X \right)\left\| {q\left( X \right)} \right.} \right] = \int_{x \in X} {\frac{{p\left( x \right)}}{{q\left( x \right)}}p\left( x \right)dx}
$$
对于第三个问题，我们借助梯度下降，通过最小化$KL\left[ {q\left( W \right)\left\| {p\left( {W\left| D \right.} \right)} \right.} \right]$来迭代更新$q\left( W \right)$的控制变量${\mathbf {\mu },\Sigma }$。下面我们借助KL散度的公式展开
$$
\begin {aligned}
KL\left[ {q\left( W \right)\left\| {p\left( {W|D} \right)} \right.} \right] 
&= \log p\left( D \right) + \int {q\left( W \right)\log \frac{{q\left( W \right)}}{{p\left( W \right)p\left( {D\left| W \right.} \right)}}dW} \\
&= \log p\left( D \right) + KL\left[ {q\left( W \right)\left\| {P\left( W \right)} \right.} \right] - {\mathbb{E}_{q\left( W \right)}}\left[ {\log p\left( {D\left| W \right.} \right)} \right]
\end {aligned}
$$
可发现$\log p\left( D \right)$一项是常数项，最小化$KL\left[ {q\left( W \right)\left\| {p\left( {W|D} \right)} \right.} \right]$等价于最小化$KL\left[ {q\left( W \right)\left\| {p\left( W \right)} \right.} \right] - {\mathbb{E}_{q\left( W \right)}}\left[ {\log p\left( {D\left| W \right.} \right)} \right]$，我们可将其作为Loss：
$$
Loss = KL\left[ {q\left( W \right)\left\| {P\left( W \right)} \right.} \right] - {\mathbb{E}_{q\left( W \right)}}\left[ {\log p\left( {D\left| W \right.} \right)} \right]
$$

> 一些文献会提及证据下界（Evidence Lower Bound，ELBO）的概念，下面说明ELBO的来历：
>
> $p\left( D \right)$一项在贝叶斯推断中被称为“证据”（Evidence），利用Jensen不等式，$\log p\left( D \right) $的下界为
> $$
> \begin{aligned}
> \log p\left( D \right) 
> &= \log \int {q\left( W \right)\frac{{p\left( {D\left| W \right.} \right)p\left( W \right)}}{{q\left( W \right)}}dW}  \hfill \\
> &\geqslant {\mathbb{E}_{q\left( W \right)}}\left[ {\log p\left( D \left| W \right. \right)} \right] - KL\left[ {q\left( W \right)\left\| {p\left( {W} \right)} \right.} \right] \hfill \\ 
> \end{aligned}
> $$
> ELBO就被定义为${\mathbb{E}_{q\left( W \right)}}\left[ {\log p\left( D \left| W \right. \right)} \right] - KL\left[ {q\left( W \right)\left\| {p\left( {W} \right)} \right.} \right]$，仅与$KL\left[ {q\left( W \right)\left\| {p\left( {W|D} \right)} \right.} \right] $差一个负号。因此，最小化$KL\left[ {q\left( W \right)\left\| {p\left( {W|D} \right)} \right.} \right] $与最大化ELBO等价。

在具体实现中，我们可以采样$W$的值。对于某个权重$w$，直接从$\mathcal{N}\left( {\mu ,\rho } \right)$采样会导致采样操作不可导（即无法知道$w$对$\mu$和$\rho$的偏导），这里需要利用运用到重参数化技巧（Reparameterization trick）来采样，其采样的流程为：

1. 采样$\varepsilon  \sim \mathcal{N}\left( {0,1} \right)$
2. $w = \mu  + \varepsilon  \times \rho$

通过这一技巧，显然$\frac{{\partial w}}{{\partial \mu }} = 1$，$\frac{{\partial w}}{{\partial \rho }} = \varepsilon$，这样可以通过梯度更新$\mu$和$\rho$了。Loss可以通过对$W$的N次采样来近似：
$$
Loss
\approx \frac{1}{N}\sum\limits_{i = 1}^N {\log q\left( {{W^{\left( i \right)}}} \right) - \log p\left( {{W^{\left( i \right)}}} \right) - \log p\left( {D\left| {{W^{\left( i \right)}}} \right.} \right)}
$$
其中先验${p\left( W \right)}$可以选取任意形式的分布，常取的先验有高斯、混合高斯、拉普拉斯等，但要注意先验的选取确实会对模型的性能产生影响，需要调参才能达到最优性能。

在得到了Loss后就可以利用梯度下降来更新网络参数了，该步骤和DNN中几乎无异，只不过需要更新的参数变为了$\mu ,\rho$。现有的深度学习代码框架（如pytorch、tensorflow等）都可以很方便地实现梯度的反向传播和参数更新。

#### 2.2.1 如何解释和计算$p\left( D \left| W \right. \right)$

似然$p\left( D \left| W \right. \right)$究竟是什么？应该如何解释，如何计算？回忆在贝叶斯推断介绍中所说，$p\left( D \left| W \right. \right)$代表了我们对$W$和$D$之间依赖关系的知识，因此对于不同的问题我们可以假设不同的似然模型。下面我们以回归问题为例说明，对于监督学习，数据集是有标签的，可以表示为$D = \left( {X,Y} \right)$，$X$表示样本输入，$Y$表示标签。对于某个输出$x$和对应的标签$y$，我们可以假设样本满足高斯似然，即$p\left( {y\left| {x,W} \right.} \right) = \mathcal{N}\left( {y;\hat y,{\tau ^{ - 1}}} \right)$，如此有
$$
\log p\left( {y\left| {x,W} \right.} \right) =  - \frac{1}{2}\tau {\left( {y - \hat y} \right)^2} + \frac{1}{2}\log \tau  - \frac{1}{2}\log 2\pi
$$
其中$\tau$代表精度（precision，方差的倒数），$\tau$实际上就反映了样本标签的噪声，如果将其作为训练参数，$\tau$就可以捕捉数据中的随机不确定性。我们发现$y$与$\hat y$越接近，${\left( {y - \hat y} \right)^2}$一项越小，似然越大，也即意味着在给定$W$时，观测到$D$的概率越大。当固定$\tau=1$，对数高斯似然就完全退化为了MSE损失函数，这就是MSE损失函数在贝叶斯观点下的解释。

对于有监督的分类问题，设类别一共有$C$种，我们通常选取softmax似然：
$$
p\left( {y = c\left| {x,W} \right.} \right) = \frac{{\exp \left( {{f_c}\left( {x\left| W \right.} \right)} \right)}}{{\sum\nolimits_{c'} {\exp \left( {{f_{c'}}\left( {x\left| W \right.} \right)} \right)} }}
$$

> **对于无监督学习，文献很少提及如何解释和确定$$p\left( D \left| W \right. \right)$$，下面是我的分析。**

我们考虑一个有模型无监督学习问题，在环境状态$s$（state）下，策略$a$（action）所产生的回报$r$（reward）可以通过已知的确定性函数$R$给出：
$$
r = R\left( {s,a} \right)
$$
我们希望BNN学习最优策略，即对于任意的$s$，BNN输出的策略分布$p\left( {\hat a\left| {s,W} \right.} \right)$能够使得期望回报最大。期望回报可以写为：
$$
\bar r = \int {R\left( {s,\hat a} \right)} p\left( {\hat a\left| {s,W} \right.} \right)d\hat a = {\mathbb{E}_{p\left( {a\left| {s,W} \right.} \right)}}\left[ {R\left( {s,a} \right)} \right]
$$
在上述有模型无监督学习问题中，变分推断的推导过程依然适用，关键在于如何解释$$p\left( D \left| W \right. \right)$$。无监督学习中，数据$D$实际上只有环境状态$s$作为输入，没有标签，不能像有监督学习那样采用高斯似然。

在有监督学习中，我们发现了MSE损失函数可以通过高斯似然来解释。由此启发，在无监督学习中我们也可以从损失函数的角度反推可能的似然。无监督学习中，我们希望$\bar r$最大，即可以选择$ - {\mathbb{E}_{p\left( {a\left| {s,W} \right.} \right)}}\left[ {R\left( {s,a} \right)} \right]$作为损失函数。很容易想到，对于某个数据样本$s$，我们可以假设似然为
$$
\log p\left( {s\left| W \right.} \right) = {\mathbb{E}_{p\left( {a\left| {s,W} \right.} \right)}}\left[ {R\left( {s,a} \right)} \right]
$$
这种似然的直观解释为：当给定策略网络参数$W$，对于输入的状态$s$，期望回报越大，那么似然也越大。

需要解释的一点是，上面给出的这个似然未归一化，我们可以根据似然概率的积分为1对其归一化。但即使不归一化也不会对其性质以及作为Loss的训练过程产生影响。

### 2.3 基于Monte  Carlo Dropout（MCDropout）的BNN实现方法

> 2012年，Hinton在其论文《Improving neural networks by preventing co-adaptation of feature detectors》中首次提出Dropout。
>
> 我们以对神经元Dropout为例：DNN在训练时，在每一次推理中，每个神经元都有$p$的概率置零（就好像该神经元被神经网络抛出了一样）并且不参与梯度更新，在DNN测试时则不会应用Dropout。
>
> Dropout可以有效地缓解DNN的过拟合问题。

实现MCDropout非常简单：不仅在训练时应用Dropout，同时在测试时也应用。这意味着在测试时，每个神经元都有$p$的概率置零，每个神经元都服从伯努利分布，进而网络参数时不确定的。对于某个输入，通过多次推理，可以得到多个不同的输出，进而可以通过统计预测值的方差来作为预测不确定性的度量。

实际上，MCDropout可以理解为一种特殊的变分推断：将每个参数近似为伯努利分布进行推断。

> 对MCDropout的详细理论分析，可以参考https://arxiv.org/pdf/1506.02157.pdf



## 三、 高斯过程（Gaussian Process，GP）

> 关于GPR的内容主要来自Bishop的《Pattern Recognition and Machine Learning》6.4节。

BNN借助神经网络的结构，通过模型参数的随机化实现对预测不确定性的度量。另一种天然地能够量化预测不确定性的方法为高斯过程。

我们下面主要以回归问题为例说明高斯过程。

### 3.1 回顾线性回归

我们从线性回归引出高斯过程。考虑一个$M$个基函数的线性组合模型：

$$
y\left( {\bf{x}} \right) = {{\bf{w}}^T}\bm\phi \left( {\bf{x}} \right)
$$

其中$\bf x$是输入向量，$\bf w$是$M$维权重向量，$\bm \phi \left( {\bf{x}} \right){\rm{ = }}\left( {{\phi _0}\left( {\bf{x}} \right), \cdots ,{\phi _{M - 1}}\left( {\bf{x}} \right)} \right)^T$，并不妨设$\bf w$的先验分布为$p\left( {\bf{w}} \right) = \mathcal N\left( {{\bf{w}}\left| {{\bf{0}},{\alpha ^{ - 1}}{\bf{I}}} \right.} \right)$。

观察到训练点${\bf x}_1,\cdots,{\bf x}_N$，我们想知道线性组合模型的输出$y_n=y\left({\bf x}_n\right),n=1,\cdots,N$的联合分布（注意这里每一个$y_n$都是标量，而${\bf x}_n$是矢量）。从线性组合模型可以知道

$$
{\bf{y}} = {\bf{\Phi w}}
$$

其中$\bf \Phi$的元素$\Phi_{nk}=\phi_k\left({\bf x}_n\right)$。由于权重是高斯的，显然输出的联合分布也是高斯的，其均值和协方差为

$$
\mathbb E\left[ {{\bf y} \left| {\bf x} \right.} \right] = {\bf{\Phi }}\mathbb E\left[ {\bf{w}} \right] = {\bf{0}}
$$

$$
{{\rm cov}} \left[ {{\bf y} \left| {\bf x} \right.} \right] = \mathbb E\left[ {{\bf{y}}{{\bf{y}}^T}} \right] = {\bf{\Phi }}\mathbb E\left[ {{\bf{w}}{{\bf{w}}^T}} \right]{{\bf{\Phi }}^T} = {\alpha ^{ - 1}}{\bf{\Phi }}{{\bf{\Phi }}^T=\bf K}
$$

$\bf K$是Gram矩阵，其元素$K_{nm}=k\left({\bf x}_n,{\bf x}_m\right)=\alpha^{-1}{\bm \phi\left({\bf x}_n\right)}^T \bm\phi\left({\bf x}_m\right)$，$k$是核函数。从$\rm cov\left[\bf y\right]$的计算式可以看出核函数满足

$$
k\left( {{{\bf{x}}_n},{{\bf{x}}_m}} \right) = \mathbb E\left[ {y\left( {{{\bf{x}}_n}} \right)y\left( {{{\bf{x}}_m}} \right)} \right]
$$

因此我们可以直接定义核函数来得到输出协方差阵的形式，而不用选择具体的基函数。常见的核函数有RBF核，Matern核等。核函数的选择对于GP至关重要，在后面，我们将看到高斯过程的预测几乎由核函数决定。

### 3.2 高斯过程回归（Gaussian Process Regression，GPR）

在实际的观测中，我们可以假设$y\left( {\bf{x}} \right) = {{\bf{w}}^T}\bm\phi \left( {\bf{x}} \right)$是无噪的的隐关系，而实际观测值则是对线性模型加入噪声得到的目标$t_n$。即可以理解为实际中获得的带噪声的样本标签为

$$
{t_n} = {y_n} + {\epsilon _n}
$$

假设噪声$\epsilon_n$是独立同分布且高斯的，给定$y_n=y\left({\bf x}_n\right),n=1,\cdots,N$，$t_n$的联合概率为

$$
p\left( {{\bf{t}}\left| {\bf{y}} \right.} \right) = \mathcal N\left( {{\bf{t}}\left| {{\bf{y}},{\sigma ^2}{{\bf{I}}_n}} \right.} \right)
$$

而$y_n$的联合概率为

$$
p\left( {\bf{y}} \right) = \mathcal N\left( {{\bf{y}}\left| {{\bf{0}},{\bf{K}}} \right.} \right)
$$

那么$t_n$的联合概率分布为

$$
p\left( {\bf{t}} \right) = \int {p\left( {{\bf{t}}\left| {\bf{y}} \right.} \right)p\left( {\bf{y}} \right)d{\bf{y}} = \mathcal N\left( {{\bf{t}}\left| {{\bf{0}},{\bf{C}}} \right.} \right)}
$$

其中

$$
{\bf{C}} = {\bf{K}} + {\sigma ^2}{{\bf{I}}_n}
$$

实际上${\bf{t}} = {\bf{y}} + {\bm{\epsilon }}$，$\bf{y}$与${\bm{\epsilon }}$是独立的，因此${\bf{t}}$的协方差为两者的协方差直接相加（这么理解更加直接且容易）。

之后我们对新的观测数据${\bf x}^*=\left({\bf x}_{n+1},\cdots,{\bf x}_{n+m+1}\right)^T$预测${\bf t}^*=\left({t}_{n+1},\cdots,{ t}_{n+m+1}\right)^T$，假设新的预测加入后的联合分布依然服从高斯分布：

$$
\left[ {\begin{array}{ccccccccccccccc}{\bf{t}}\\{{{\bf{t}}^*}}\end{array}} \right] \sim \mathcal N\left( {{\bf{0}},\left[ {\begin{array}{ccccccccccccccc}{{\bf{C}}\left( {{\bf{x}},{\bf{x}}} \right)}&{{\bf{K}}\left( {{\bf{x}},{{\bf{x}}^*}} \right)}\\{{\bf{K}}\left( {{{\bf{x}}^*},{\bf{x}}} \right)}&{{\bf{C}}\left( {{{\bf{x}}^*},{{\bf{x}}^*}} \right)}\end{array}} \right]} \right)
$$

> 多维高斯分布的条件概率如下：
>
> 若
>
> $$
> \left[ {\begin{array}{ccccccccccccccc}{\bf{x}}\\{\bf{y}}\end{array}} \right] \sim {\mathcal N}\left( {\left[ {\begin{array}{ccccccccccccccc}{{{\bm{\mu }}_x}}\\{{{\bm{\mu }}_y}}\end{array}} \right],\left[ {\begin{array}{ccccccccccccccc}{\bf{A}}&{\bf{C}}\\{{{\bf{C}}^T}}&{\bf{B}}\end{array}} \right]} \right)
> $$
>
> 则
>
> $$
> {\bf{x}}\left| {\bf{y}} \sim {\mathcal N}\left( {{{\bm{\mu }}_x} + {\bf{C}}{{\bf{B}}^{ - 1}}\left( {{\bf{y}} - {{\bm{\mu }}_y}} \right),{\bf{A}} - {\bf{C}}{{\bf{B}}^{ - 1}}{{\bf{C}}^T}} \right) \right.
> $$

根据多维高斯的条件分布公式，可得

$$
\mathbb E\left[ {{{\bf{t}}^*}\left| {\bf{t}} \right.} \right] = {\bf{K}}\left( {{{\bf{x}}^*},{\bf{x}}} \right){\bf{C}}{\left( {{\bf{x}},{\bf{x}}} \right)^{ - 1}}{\bf{t}}
$$

$$
{\bf{Cov}}\left[ {{{\bf{t}}^*}\left| {\bf{t}} \right.} \right] = {\bf{C}}\left( {{{\bf{x}}^*},{{\bf{x}}^*}} \right) - {\bf{K}}\left( {{{\bf{x}}^*},{\bf{x}}} \right){\bf{C}}{\left( {{\bf{x}},{\bf{x}}} \right)^{ - 1}}{\bf{K}}\left( {{\bf{x}},{{\bf{x}}^*}} \right)
$$

这就得到了预测值的均值和协方差。我们看到，在计算预测值的时候需要对一个$N\times N$的矩阵$\bf C$求逆，这会带来$O\left( N^3\right)$的计算复杂度和$O\left( N^2\right)$的空间复杂度。

### 3.3 核学习的概念

从上面的推导中，我们发现高斯过程的预测很大程度由核函数决定，可以说核函数决定了高斯过程的预测性能。因此，与其将核函数定死，不如将核函数部分参数化，然后通过数据来学习参数。比如，RBF的一种形式为${k_{{\text{RBF}}}}\left( {{\bf x},{\bf x'}} \right) = \exp \left( { - \frac{1}{2}\left\| {{\bf x} - \bf x'} \right\|/{l^2}} \right)$，其中的$l$就是一个长度尺度超参数。

核函数的超参数可以基于最大化边缘似然来学习。设核函数的超参数为$\bf \gamma$，对数边缘似然函数可以表示为
$$
\ln p\left( {{\mathbf{t}}\left| {\mathbf{\gamma }} \right.} \right) =  - \frac{1}{2}\ln \left| {{{\mathbf{K}}_\gamma+\sigma^2I}} \right| - \frac{1}{2}{{\mathbf{t}}^T}\left({\mathbf{K}}_\gamma+\sigma^2I\right)^{ - 1}{\mathbf{t}} - \frac{N}{2}\ln \left( {2\pi } \right)
$$
> 参考文献：Guassian Process for Machine Learning, C. E. Rasmussen等, 5.4节。文中对“**边缘似然**”的解释是：当前超参数$\bf \gamma$作为**边缘**，在已知输入为$\bf x$的条件下的**似然**。

其中$-{{\mathbf{t}}^T}{\left( {{{\mathbf{K}}_\gamma } + {\sigma ^2}{\mathbf{I}}} \right)^{ - 1}}{\mathbf{t}}/2$一项代表数据拟合程度，$\ln \left| {{{\mathbf{K}}_\gamma } + {\sigma ^2}{\mathbf{I}}} \right|/2$则是复杂度惩罚项。我们通常用梯度法迭代更新超参数来最大化边缘似然。不妨将$\sigma^2I$这一项视为超参数的一部分，可将${{{\mathbf{K}}_\gamma } + {\sigma ^2}{\mathbf{I}}}$简记为${{{\mathbf{K}}_\gamma }}$。这样，可以得到边缘似然函数的关于超参数的梯度表达式：
$$
\begin{gathered}
  \frac{\partial }{{\partial {\gamma _j}}}\log p\left( {{\mathbf{t}}\left| {\mathbf{\gamma }} \right.} \right) = \frac{1}{2}{{\mathbf{t}}^T}{\mathbf{K}}_\gamma ^{ - 1}\frac{{\partial {{\mathbf{K}}_\gamma }}}{{\partial {\gamma _j}}}{\mathbf{K}}_\gamma ^{ - 1}{\mathbf{t}} - \frac{1}{2}\operatorname{tr} \left( {{\mathbf{K}}_\gamma ^{ - 1}\frac{{\partial {{\mathbf{K}}_\gamma }}}{{\partial {\gamma _j}}}} \right) \\ 
   = \frac{1}{2}\operatorname{tr} \left( {\left( {{\mathbf{\alpha }}{{\mathbf{\alpha }}^T} - {\mathbf{K}}_\gamma ^{ - 1}} \right)\frac{{\partial {{\mathbf{K}}_\gamma }}}{{\partial {\gamma _j}}}} \right),\;where\;{\mathbf{\alpha }} = {\mathbf{K}}_\gamma ^{ - 1}{\mathbf{t}} \\ 
\end{gathered}
$$
可见，该梯度计算式包含求逆，计算复杂度较高（$O\left( N^3\right)$），一般需要利用一些近似算法来加速学习，比如诱导点法。

此外，通过梯度法，以最大化边缘似然来迭代更新超参数不保证能收敛到全局最大点，但经验表明这并不是一个灾难性的问题，与SGD更新神经网络权重的结果类似，收敛到局部最优点的性能一般依然不错，只需注意不要收敛到过于差的点即可。

### 3.4 近似GP

> 参考文献：A Unifying View of Sparse Approximate Gaussian Process Regression, Rasmussen等

为了降低GP的计算复杂度，我们通常需要利用一些近似方法。我们下面介绍诱导点法。

首先引入隐变量集合${\mathbf{u}} = {\left[ {{u_1}, \cdots ,{u_m}} \right]^T}$，这些隐变量是高斯过程可能的输出（就像$\bf y$一样），我们将这种隐变量叫做**诱导变量**，并且这些诱导变量都对应着输入${X_{\mathbf{u}}}$，我们将这些输入叫做**诱导输入**。诱导变量和诱导输入有时候会被称作支持点、主动点集或是伪输入。不同的稀疏近似算法会用不同方法选取诱导变量，一些方法会从训练集中选取一个子集作为诱导输入，另外一些则不。

引入诱导变量后，测试集和训练集的联合分布可以写为（注：方便起见，这里我们先不考虑观测噪声）
$$
p\left( {{{\mathbf{y}}^*},{\mathbf{y}}} \right) = \int {p\left( {{{\mathbf{y}}^*},{\mathbf{y}}\left| {\mathbf{u}} \right.} \right)p\left( {\mathbf{u}} \right)d{\mathbf{u}}} ,\;where\;p\left( {\mathbf{u}} \right) = \mathcal{N}\left( {{\mathbf{0}},{K_{{\mathbf{u}},{\mathbf{u}}}}} \right)
$$

在几乎所有的近似方法中，都假设$\bf y^*$和$\bf y$关于$\bf u$是条件独立的，由此
$$
p\left( {{{\mathbf{y}}^*},{\mathbf{y}}} \right) \simeq q\left( {{{\mathbf{y}}^*},{\mathbf{y}}} \right) = \int {q\left( {{{\mathbf{y}}^*}\left| {\mathbf{u}} \right.} \right)q\left( {{\mathbf{y}}\left| {\mathbf{u}} \right.} \right)p\left( {\mathbf{u}} \right)d{\mathbf{u}}}
$$
现在我们可以解释**诱导**的含义：$\bf u$诱导了训练集$\bf y$和测试集$\bf y^*$之间的依赖关系。$\bf y$和$\bf y^*$关于$\bf u$确切的条件概率为
$$
p\left( {{\mathbf{y}}\left| {\mathbf{u}} \right.} \right) = \mathcal{N}\left( {{K_{{\mathbf{y}},{\mathbf{u}}}}K_{{\mathbf{u}},{\mathbf{u}}}^{ - 1}{\mathbf{u}},{K_{{\mathbf{y}},{\mathbf{y}}}} - {Q_{{\mathbf{y}},{\mathbf{y}}}}} \right)
$$

$$
p\left( {{{\mathbf{y}}^*}\left| {\mathbf{u}} \right.} \right) = \mathcal{N}\left( {{K_{{{\mathbf{y}}^*},{\mathbf{u}}}}K_{{\mathbf{u}},{\mathbf{u}}}^{ - 1}{\mathbf{u}},{K_{{{\mathbf{y}}^*},{{\mathbf{y}}^*}}} - {Q_{{{\mathbf{y}}^*},{{\mathbf{y}}^*}}}} \right)
$$

其中${Q_{{\mathbf{a}},{\mathbf{b}}}} \triangleq {K_{{\mathbf{a}},{\mathbf{u}}}}K_{{\mathbf{u}},{\mathbf{u}}}^{ - 1}{K_{{\mathbf{u}},{\mathbf{b}}}}$。

后面我们将看到，不同的近似方法会提出不同的附加假设来近似地给出$q\left( {{{\mathbf{y}}^*}\left| {\mathbf{u}} \right.} \right)$和$q\left( {{{\mathbf{y}}}\left| {\mathbf{u}} \right.} \right)$，使得计算过程更高效。

#### 3.4.1 The Subset of Regressors (SoR) Approximation

SoR方法将对应于输入$\bf x^*$的输出$y^*$近似地建模为关于核函数$K_{y^*,\bf u}$的线性组合，即
$$
{y^*} = {K_{{y^*},{\mathbf{u}}}}{{\mathbf{w}}_{\mathbf{u}}}
$$
并且将${\mathbf{w}}_{\mathbf{u}}$的先验分布设为了$p\left( {{{\mathbf{w}}_{\mathbf{u}}}} \right) = \mathcal{N}\left( {{\mathbf{0}},K_{{\mathbf{u}},{\mathbf{u}}}^{ - 1}} \right)$，通过下面的式子我们将看到这么设置其先验协方差的合理性。
$$
{\mathbf{u}} = {K_{{\mathbf{u}},{\mathbf{u}}}}{{\mathbf{w}}_{\mathbf{u}}} \Rightarrow \left\langle {{\mathbf{u}}{{\mathbf{u}}^T}} \right\rangle  = {K_{{\mathbf{u}},{\mathbf{u}}}}\left\langle {{{\mathbf{w}}_{\mathbf{u}}}{\mathbf{w}}_{\mathbf{u}}^T} \right\rangle {K_{{\mathbf{u}},{\mathbf{u}}}} = {K_{{\mathbf{u}},{\mathbf{u}}}}
$$
可见，将${\mathbf{w}}_{\mathbf{u}}$的先验协方差设为${K_{{\mathbf{u}},{\mathbf{u}}}^{ - 1}}$才能恢复诱导变量$\bf u$的先验协方差。

注意到${{\mathbf{w}}_{\mathbf{u}}} = K_{{\mathbf{u}},{\mathbf{u}}}^{ - 1}{\mathbf{u}}$，我们可以将SoR近似模型写为更直观的形式：
$$
{{\mathbf{y}}^*} = {K_{{{\mathbf{y}}^*},{\mathbf{u}}}}K_{{\mathbf{u}},{\mathbf{u}}}^{ - 1}{\mathbf{u}}
$$
这说明SoR模型中的$\mathbf{y}^*$和$\bf u$是确定性的关系，容易理解由此近似的$q\left( {{{\mathbf{y}}^*}\left| {\mathbf{u}} \right.} \right)$和$q\left( {{{\mathbf{y}}}\left| {\mathbf{u}} \right.} \right)$的协方差为0：
$$
{q_{SoR}}\left( {{\mathbf{y}}\left| {\mathbf{u}} \right.} \right) = \mathcal{N}\left( {{K_{{\mathbf{y}},{\mathbf{u}}}}K_{{\mathbf{u}},{\mathbf{u}}}^{ - 1}{\mathbf{u}},{\mathbf{0}}} \right)
$$

$$
{q_{SoR}}\left( {{{\mathbf{y}}^*}\left| {\mathbf{u}} \right.} \right) = \mathcal{N}\left( {{K_{{{\mathbf{y}}^*},{\mathbf{u}}}}K_{{\mathbf{u}},{\mathbf{u}}}^{ - 1}{\mathbf{u}},{\mathbf{0}}} \right)
$$

根据多维高斯的条件分布公式，可得
$$
{q_{SoR}}\left( {{\mathbf{y}},{{\mathbf{y}}^*}} \right) = \mathcal{N}\left( {{\mathbf{0}},\left[ {\begin{array}{*{20}{c}}
  {{Q_{{\mathbf{y}},{\mathbf{y}}}}}&{{Q_{{\mathbf{y}},{{\mathbf{y}}^*}}}} \\ 
  {{Q_{{{\mathbf{y}}^*},{\mathbf{y}}}}}&{{Q_{{{\mathbf{y}}^*},{{\mathbf{y}}^*}}}} 
\end{array}} \right]} \right)
$$
回忆起${Q_{{\mathbf{a}},{\mathbf{b}}}} \triangleq {K_{{\mathbf{a}},{\mathbf{u}}}}K_{{\mathbf{u}},{\mathbf{u}}}^{ - 1}{K_{{\mathbf{u}},{\mathbf{b}}}}$，并对照之前GP的推导结果：
$$
p\left( {{\mathbf{y}},{{\mathbf{y}}^*}} \right) = \mathcal{N}\left( {{\mathbf{0}},\left[ {\begin{array}{*{20}{c}}
  {{K_{{\mathbf{y}},{\mathbf{y}}}}}&{{K_{{\mathbf{y}},{{\mathbf{y}}^*}}}} \\ 
  {{K_{{{\mathbf{y}}^*},{\mathbf{y}}}}}&{{K_{{{\mathbf{y}}^*},{{\mathbf{y}}^*}}}} 
\end{array}} \right]} \right)
$$
不难发现，SoR方法实际上用了等效核函数代替原核函数：
$$
{k_{SoR}}\left( {{{\mathbf{x}}_i},{{\mathbf{x}}_j}} \right) = k\left( {{{\mathbf{x}}_i},{\mathbf{u}}} \right)K_{{\mathbf{u}},{\mathbf{u}}}^{ - 1}k\left( {{\mathbf{u}},{{\mathbf{x}}_j}} \right)
$$
新的核函数的秩最高为$m$（诱导点数），计算复杂度降为$O\left( Nm^2\right)$。从上式也能看出，新的等效核函数的具体形式和诱导点的具体位置有关。

#### 3.4.2 The Fully Independent Training Conditional (FITC) Approximation

> FITC在最初由Snelson等人提出时被称作SPGP(sparse pseudo-input Gaussian process)

与SoR不同，FITC并不假设$\mathbf{y}^*$和$\bf u$有确定性函数关系，而是假设训练样本关于$\bf u$条件独立，即把$q\left( {{{\mathbf{y}}}\left| {\mathbf{u}} \right.} \right)$近似为：
$$
{q_{FITC}}\left( {{\mathbf{y}}\left| {\mathbf{u}} \right.} \right) = \prod\limits_{i = 1}^n {p\left( {{y_i}\left| {\mathbf{u}} \right.} \right)}  = \mathcal{N}\left( {{K_{{\mathbf{y}},{\mathbf{u}}}}K_{{\mathbf{u}},{\mathbf{u}}}^{ - 1}{\mathbf{u}},\operatorname{diag} \left( {{K_{{\mathbf{y}},{\mathbf{y}}}} - {Q_{{\mathbf{y}},{\mathbf{y}}}}} \right)} \right)
$$
我们先考虑单一测试样本，FITC的$q\left( {{{{y^*}}}\left| {\mathbf{u}} \right.} \right)$为：
$$
{q_{FITC}}\left( {{{{y}}^*}\left| {\mathbf{u}} \right.} \right) = p\left( {{{{y}}^*}\left| {\mathbf{u}} \right.} \right)
$$
同样地，可以给出
$$
{q_{FITC}}\left( {{\mathbf{y}},{y^*}} \right) = \mathcal{N}\left( {{\mathbf{0}},\left[ {\begin{array}{*{20}{c}}
  {{Q_{{\mathbf{y}},{\mathbf{y}}}} - \operatorname{diag} \left( {{Q_{{\mathbf{y}},{\mathbf{y}}}} - {K_{{\mathbf{y}},{\mathbf{y}}}}} \right)}&{{Q_{{\mathbf{y}},{y^*}}}} \\ 
  {{Q_{{y^*},{\mathbf{y}}}}}&{{K_{{y^*},{y^*}}}} 
\end{array}} \right]} \right)
$$
如果进一步假设测试样本也关于$\bf u$条件独立，那么FITC就变为FIC（fully independent conditional），可以写出FIC的等效核函数为
$$
{k_{FIC}}\left( {{{\mathbf{x}}_i},{{\mathbf{x}}_j}} \right) = {k_{SoR}}\left( {{{\mathbf{x}}_i},{{\mathbf{x}}_j}} \right) + {\delta _{i,j}}\left( {k\left( {{{\mathbf{x}}_i},{{\mathbf{x}}_j}} \right) - {k_{SoR}}\left( {{{\mathbf{x}}_i},{{\mathbf{x}}_j}} \right)} \right)
$$
FITC和FIC的计算复杂度与SoR一致。

#### 3.4.3 Kernel Interpolation for Scalable Structured Gaussian Processes(KISS-GP)

> 参考文献：Kernel Interpolation for Scalable Structured Gaussian Processes(KISS-GP), Andrew Gordon Wilson等

KISS-GP是一种加速GP训练的方法，主要思路是选取诱导点，对核矩阵进行结构化核插值（structured kernel interpolation, SKI）来近似，再利用近似矩阵的Kronecker或Toeplitz结构进一步简化求逆运算。但需要注意的是，输入必须是1维的才能利用Toeplitz结构，而如果利用Kronecker结构则在输入维度低于5时才比较高效。

通过SKI，$m$个诱导点可以将核矩阵求逆运算的计算复杂度降低到$O\left(N+m^2\right)$，进一步利用Kronecker结构则可以降低到$O\left(Pm^\left(1+1/P\right)\right)$($P$是输入点的维数)，利用Toeplitz结构则可以降低到$O\left(N+m\log m\right)$。

#### 3.4.4 如何确定诱导点及其分布——变分法，近似推断GP

> 参考文献：Gaussian Process for Big Data, Hensman等

在SoR和FITC中，我们虽然知道$p\left( {\mathbf{u}} \right) = \mathcal{N}\left( {{\mathbf{0}},{K_{{\mathbf{u}},{\mathbf{u}}}}} \right)$，但是该分布的协方差由$\bf u$的具体位置决定，无法通过该式来采样诱导点。我们考虑通过变分法，通过最大化训练集的似然来学习得到$p\left( {\mathbf{u}} \right)$的近似分布$q\left( {\mathbf{u}} \right)$。
$$
\begin{gathered}
  \log p\left( {{\mathbf{t}}\left| {\mathbf{X}} \right.} \right) = \log \int {p\left( {{\mathbf{t}}\left| {\mathbf{u}} \right.} \right)} \frac{{p\left( {\mathbf{u}} \right)}}{{q\left( {\mathbf{u}} \right)}}q\left( {\mathbf{u}} \right)d{\mathbf{u}} \\ 
   \geqslant {\left\langle {\log p\left( {{\mathbf{t}}\left| {\mathbf{u}} \right.} \right) + \log p\left( {\mathbf{u}} \right) - \log q\left( {\mathbf{u}} \right)} \right\rangle _{q\left( {\mathbf{u}} \right)}} \\ 
\end{gathered}
$$
我们将该下界记为$\mathcal L$
$$
\mathcal{L} = {\left\langle {\log p\left( {{\mathbf{t}}\left| {\mathbf{u}} \right.} \right) + \log p\left( {\mathbf{u}} \right) - \log q\left( {\mathbf{u}} \right)} \right\rangle _{q\left( {\mathbf{u}} \right)}}
$$
我们将近似分布的形式设为
$$
q\left( {\mathbf{u}} \right) = \mathcal{N}\left( {{\mathbf{m}},{\mathbf{S}}} \right)
$$
对$\mathcal L$关于$\bf m$和$\bf S$求偏导，可得
$$
\frac{{\partial \mathcal{L}}}{{\partial {\mathbf{m}}}} = {\sigma ^{ - 2}}{\mathbf{K}}_{mm}^{ - 1}{{\mathbf{K}}_{mn}}{\mathbf{t}} - {\mathbf{\Lambda m}}
$$

$$
\frac{{\partial \mathcal{L}}}{{\partial {\mathbf{S}}}} = \frac{1}{2}{{\mathbf{S}}^{ - 1}} - \frac{1}{2}{\mathbf{\Lambda }}
$$

其中${\mathbf{\Lambda }} = {\sigma ^{ - 2}}{\mathbf{K}}_{mm}^{ - 1}{{\mathbf{K}}_{mn}}{{\mathbf{K}}_{nm}}{\mathbf{K}}_{mm}^{ - 1} + {\mathbf{K}}_{mm}^{ - 1}$，${{\mathbf{K}}_{mm}}$是所有诱导点之间的协方差阵，${{\mathbf{K}}_{mn}}$是所有诱导点和训练点之间的协方差阵。

由此，通过变分法，我们可以用梯度下降法来更新$q\left( {\mathbf{u}} \right)$的分布，最终找到一个合适的近似。通过这种方法训练的GP也称为**近似推断的GP**。

### 3.5 多输出的GP

> 参考文献：Remarks on multi-output Gaussian process regression, Haitao Liu等

在前面介绍GPR时，假设了输出是个标量，即单输出的GPR。对于输出是多维的任务，一种直接的方法是将输出的每一维都视作单输出GPR来学习，但这样的坏处是没有建模输不同维度之间的相关性，会导致性能损失。因此，对于多输出的GPR，建模输出不同维度之间的相关性是关键，下面我们将通过推导证明这一观点。

我们假设训练集为$X = \left\{ {{{\mathbf{x}}_1}, \cdots ,{{\mathbf{x}}_N}} \right\}$，对于每一条输入${\bf x}_n$都有$L$维的输出${\left\{ {{y_{n,l}}} \right\}_{1 \leqslant l \leqslant L}}$，观测的每一维为${t_{n,l}} = {y_{n,l}} + \epsilon _l$，$\epsilon_l  \sim \mathcal{N}\left( {0,\sigma _l^2} \right)$，那么
$$
p\left( {{\mathbf{t}}\left| {\mathbf{y}} \right.} \right) = \mathcal{N}\left( {{\mathbf{y}},{\Sigma _s}} \right)
$$
其中
$$
{\Sigma _s} = \operatorname{diag} \left( {\sigma _1^2, \cdots ,\sigma _L^2} \right) \in {\mathbb{R}^{L \times L}}
$$
将单输出的核函数进行拓展，多输出GPR的核函数的定义为
$$
{{\mathcal K}_M}\left( {{\mathbf{x}},{\mathbf{x'}}} \right) = \left[ {\begin{array}{*{20}{c}}
  {{k_{11}}\left( {{\mathbf{x}},{\mathbf{x'}}} \right)}& \cdots &{{k_{1L}}\left( {{\mathbf{x}},{\mathbf{x'}}} \right)} \\ 
   \vdots & \ddots & \vdots  \\ 
  {{k_{L1}}\left( {{\mathbf{x}},{\mathbf{x'}}} \right)}& \cdots &{{k_{LL}}\left( {{\mathbf{x}},{\mathbf{x'}}} \right)} 
\end{array}} \right]\in {\mathbb{R}^{L \times L}}
$$
其中${k_{ll'}}\left( {{\mathbf{x}},{\mathbf{x'}}} \right) = \mathbb{E}\left[ {{y_l}\left( {\mathbf{x}} \right){y_{l'}}\left( {{\mathbf{x'}}} \right)} \right]$。类似单输出GPR的推导，可得对于一条测试输入${\bf x}^*$的预测满足$L$维高斯分布，均值和方差分别为
$$
\mathbb{E}\left[ {{{\mathbf{t}}^*}\left| {\mathbf{t}} \right.} \right] = K_{M*}^T{\left[ {{K_M}\left( {X,X} \right) + {\Sigma _M}} \right]^{ - 1}}{\bf t}
$$

$$
{\mathbf{Cov}}\left[ {{{\mathbf{t}}^*}\left| {\mathbf{t}} \right.} \right] = {\mathcal K_M}\left( {{{\mathbf{x}}^*},{{\mathbf{x}}^*}} \right) + \Sigma_s - K_{M*}^T{\left[ {{K_M}\left( {X,X} \right) + {\Sigma _M}} \right]^{ - 1}}{K_{M*}}
$$

其中
$$
K_{M*} = {K_M}\left( {X,{{\mathbf{x}}^*}} \right) = \left[ {\begin{array}{*{20}{c}}
  {{\mathcal{K}_M}\left( {{{\mathbf{x}}_1},{{\mathbf{x}}^*}} \right)} \\ 
   \vdots  \\ 
  {{\mathcal{K}_M}\left( {{{\mathbf{x}}_N},{{\mathbf{x}}^*}} \right)} 
\end{array}} \right] \in {\mathbb{R}^{NL \times L}}
$$

$$
{K_M}\left( {X,X} \right) = \left[ {\begin{array}{*{20}{c}}
  {{\mathcal{K}_M}\left( {{{\mathbf{x}}_1},{{\mathbf{x}}_1}} \right)}& \cdots &{{\mathcal{K}_M}\left( {{{\mathbf{x}}_1},{{\mathbf{x}}_N}} \right)} \\ 
   \vdots & \ddots & \vdots  \\ 
  {{\mathcal{K}_M}\left( {{{\mathbf{x}}_N},{{\mathbf{x}}_1}} \right)}& \cdots &{{\mathcal{K}_M}\left( {{{\mathbf{x}}_N},{{\mathbf{x}}_N}} \right)} 
\end{array}} \right] \in {\mathbb{R}^{NL \times NL}}
$$

$$
{\Sigma _M} = {\Sigma _s} \otimes {{\mathbf{I}}_n} \in {\mathbb{R}^{NL \times NL}}
$$

类似单输出GPR，多输出GPR的预测几乎取决于核函数${k_{ll'}}\left( {{\mathbf{x}},{\mathbf{x'}}} \right)$。不同点在于，单输出GPR的核函数只有一个，而多输出GPR需要对输出的每一维之间的协方差进行建模，实际上有$L \times L$个核函数。如何去建模输出的不同维之间的相关性，并决定核函数的形式，是多输出GPR的关键。



## 四、 深度核学习（Deep Kernel Learning，DKL）

> 我接触DKL也才不久，对于DKL这部分的理解较为粗浅，可能会有理解不对的地方。如果希望深入了解DKL可以阅读后面推荐的两篇参考文献。

我们在介绍核学习时提到，与其将核函数定死，不如将核函数部分参数化，然后通过数据来学习参数。但是，即使部分参数化了，核函数的形式依然需要我们决定（比如多项式核、高斯核等形式）。那么我们能否利用深度神经网络来学习核函数的具体形式呢？这就是DKL的基本思想。

### 4.1 Exact DKL

> 参考文献：Deep Kernel Learning, Andrew Gordon Wilson等

DKL的主要思路是，利用神经网络辅助构造一个核函数。我们先利用深度神经网络$g$对输入进行非线性映射，再输入原来的核函数$k\left( {{{\mathbf{x}}_i},{{\mathbf{x}}_j}\left| {\mathbf{\theta }} \right.} \right)$，即
$$
k\left( {{{\mathbf{x}}_i},{{\mathbf{x}}_j}\left| {\mathbf{\theta }} \right.} \right) \to k\left( {g\left( {{{\mathbf{x}}_i},{\mathbf{w}}} \right),g\left( {{{\mathbf{x}}_j},{\mathbf{w}}} \right)\left| {\mathbf{\theta }} \right.,{\mathbf{w}}} \right)
$$
我们可以理解为，通过神经网络的映射构造出了一个新的核函数，新的核函数的超参数为${\mathbf{\gamma }} = \left\{ {{\mathbf{w}},{\mathbf{\theta }}} \right\}$。

我们不妨将$\sigma^2I$这一项视为超参数$\bf \theta$的一部分，这样对数似然函数可以写为
$$
\mathcal L=\ln p\left( {{\mathbf{t}}\left| {\mathbf{\gamma }} \right.} \right) =  - \frac{1}{2}\ln \left| {{{\mathbf{K}}_\gamma}} \right| - \frac{1}{2}{{\mathbf{t}}^T}{\mathbf{K}}_\gamma^{ - 1}{\mathbf{t}} + const
$$
对$\bf \theta$和$\bf w$求偏导，有
$$
\frac{{\partial \mathcal{L}}}{{\partial {\mathbf{\theta }}}} = \frac{{\partial \mathcal{L}}}{{\partial {{\mathbf{K}}_\gamma }}}\frac{{\partial {{\mathbf{K}}_\gamma }}}{{\partial {\mathbf{\theta }}}},\quad \frac{{\partial \mathcal{L}}}{{\partial {\mathbf{w}}}} = \frac{{\partial \mathcal{L}}}{{\partial {{\mathbf{K}}_\gamma }}}\frac{{\partial {{\mathbf{K}}_\gamma }}}{{\partial g\left( {{\mathbf{x}},{\mathbf{w}}} \right)}}\frac{{\partial g\left( {{\mathbf{x}},{\mathbf{w}}} \right)}}{{\partial {\mathbf{w}}}}
$$
其中$\frac{{\partial {{\mathbf{K}}_\gamma }}}{{\partial {\mathbf{\theta }}}}$和$\frac{{\partial {{\mathbf{K}}_\gamma }}}{{\partial g\left( {{\mathbf{x}},{\mathbf{w}}} \right)}}$均根据核函数的具体形式可以得到显式解，而$\frac{{\partial g\left( {{\mathbf{x}},{\mathbf{w}}} \right)}}{{\partial {\mathbf{w}}}}$则可以通过神经网络的反向传播计算。$\frac{{\partial \mathcal{L}}}{{\partial {{\mathbf{K}}_\gamma }}}$可以写为
$$
\frac{{\partial \mathcal{L}}}{{\partial {{\mathbf{K}}_\gamma }}} = \frac{1}{2}\left( {{\mathbf{K}}_\gamma ^{ - 1}{\mathbf{t}}{{\mathbf{t}}^T}{\mathbf{K}}_\gamma ^{ - 1} - {\mathbf{K}}_\gamma ^{ - 1}} \right)
$$

Exact DKL的不足之处在于：不支持随机训练、多输出、不适合输出过多特征的神经网络结构（这一点是由于采用KISS-GP导致的）以及不能用于分类任务。

### 4.2 Stochastic Variational Deep Kernel Learning(SV-DKL)

> 参考文献：Stochastic Variational Deep Kernel Learning, Andrew Gordon Wilson等

SV-DKL与Exact DKL的区别在于Exact DKL用的是精确推断的GP（Exact inference GP），而SV-DKL用的是近似推断的GP（Approximate inference GP）。此外，SV-DKL引入了多个GP。

SV-DKL的主要结构：

- 一个深度非线性网络${\bf h} \left({\bf x}, {\bf w}\right)$，将输入映射为$Q$个特征
- $J$个GP，核函数分别是$k_1,\dots,k_J$
- 通过矩阵$A \in \mathbb R^{C \times J}$将GP线性组合，输出$y_1,\dots,y_C$

利用近似推断，SV-DKL支持随机训练和输出较多维特征的神经网络；通过引入多个GP，SV-DKL支持多输出和分类任务。

